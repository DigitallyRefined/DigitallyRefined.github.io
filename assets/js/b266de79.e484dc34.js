"use strict";(globalThis.webpackChunkdigitally_refined=globalThis.webpackChunkdigitally_refined||[]).push([[518],{4369(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/guides/PVE-unprivileged-LXC-rootless-containers","metadata":{"permalink":"/guides/PVE-unprivileged-LXC-rootless-containers","editUrl":"https://github.com/DigitallyRefined/DigitallyRefined.github.io/tree/main/blog/2026-02-04-PVE-unprivileged-LXC-rootless-containers.mdx","source":"@site/blog/2026-02-04-PVE-unprivileged-LXC-rootless-containers.mdx","title":"Running rootless Docker on a Proxmox unprivileged LXC","description":"By default Proxmox unprivileged LXC containers only allow running Docker/Podman as root. In this guide we will set up rootless Docker inside an unprivileged LXC container.","date":"2026-02-04T00:00:00.000Z","tags":[{"inline":true,"label":"Proxmox","permalink":"/tags/proxmox"},{"inline":true,"label":"LXC","permalink":"/tags/lxc"},{"inline":true,"label":"Self-hosting","permalink":"/tags/self-hosting"},{"inline":true,"label":"Docker","permalink":"/tags/docker"}],"readingTime":10.12,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"/guides/PVE-unprivileged-LXC-rootless-containers","tags":["Proxmox","LXC","Self-hosting","Docker"],"last_update":{"date":"2026-02-06T00:00:00.000Z"}},"unlisted":false,"lastUpdatedAt":1770336000000,"nextItem":{"title":"Containers Up!","permalink":"/guides/Containers-Up"}},"content":"By default Proxmox unprivileged LXC containers only allow running Docker/Podman as `root`. In this guide we will set up rootless Docker inside an unprivileged LXC container.\\n\\nAllowing nesting namespaces three levels deep:<br/>\\n**Proxmox Host** \u2192 **Unprivileged LXC** \u2192 **Rootless Docker/Podman** \u2192 **Docker in Docker (DinD)**.\\n\\n{/* truncate */}\\n\\nRunning Docker or Podman as root can be a bit of a security risk, especially as we\'ve seen quite an increase in malware such as the [Shai-Hulud worm](https://www.microsoft.com/en-us/security/blog/2025/12/09/shai-hulud-2-0-guidance-for-detecting-investigating-and-defending-against-the-supply-chain-attack/) and AI tools like [OpenClaw](https://github.com/openclaw/openclaw) gaining full access to your machine.\\n\\nRunning containers in an unprivileged LXC containers with rootless Docker/Podman adds an extra layer of security and reduces the blast radius, as even if a container is compromised, the attacker would still be limited by the unprivileged LXC and standard/non-admin user restrictions.\\n\\nimport TOCInline from \'@theme/TOCInline\';\\n\\n<TOCInline toc={toc} />\\n\\n## Installation\\n\\nAfter creating an unprivileged LXC container, first we\'ll need to navigate to our Proxmox dashboard and open up a console on the host.\\n\\nNow we can run the [PVE LXC Unprivileged Rootless Docker script](https://gist.github.com/DigitallyRefined/37dfcc68a146c59e2215c2b5b5fabecc):\\n\\n```bash\\nbash -c \\"$(curl -fsSL https://gist.githubusercontent.com/DigitallyRefined/37dfcc68a146c59e2215c2b5b5fabecc/raw/pve-unprivileged-lxc-rootless-containers.sh)\\"\\n```\\n\\n:::warning\\nPlease [review the script](https://gist.github.com/DigitallyRefined/37dfcc68a146c59e2215c2b5b5fabecc) before running it before running it on your system.\\n\\nThis script has been tested with a Debian 13 LXC on Proxmox 9.1.\\n:::\\n\\nReview the list of LXC containers and confirm that you want to continue, select `Yes` on the GPU prompt and select the LXC container we created earlier from the list, once you confirm the script will run through the LXC containers adjusting the namespaces that we can use containers and container nesting (Docker in Docker) via non-root users.\\n\\nOnce the script finishes updating the namespace, we need to SSH into the LXC container as root and install Docker and the `uidmap` package and create a non-root user to run rootless Docker:\\n\\n```bash\\nssh root@192.168...\\n\\nwget -qO get-docker.sh https://get.docker.com\\nsh get-docker.sh\\n\\napt install -y uidmap\\n\\nadduser user\\n\\nexit\\n```\\n\\nNow that we have Docker installed, we can SSH into the container as the non-root user we created (`test` in this case) and set up rootless Docker and test that it works correctly:\\n\\n```bash\\nssh user@192.168...\\n\\ndockerd-rootless-setuptool.sh install\\n\\ndocker run --rm hello-world\\n```\\n\\nIf this works correctly, you should see a \\"Hello from Docker!\\" message confirming that rootless Docker is working inside the unprivileged LXC container.\\n\\nNow that we\'ve confirmed rootless Docker is working, we can allow the Docker service to start on boot for the non-root user and disable the root Docker service:\\n\\n```bash\\nssh root@192.168...\\nloginctl enable-linger user # replace \'user\' with your non-root username\\n\\nsystemctl stop docker.service docker.socket\\nsystemctl disable docker.service docker.socket\\nsystemctl stop containerd.service\\nsystemctl disable containerd.service\\n```\\n\\n## Video transcoding\\n\\nNow we have rootless Docker set up and working, we can try running a more complex container that uses hardware acceleration. In this example we\'ll use the `linuxserver/ffmpeg` container to generate a test video via the GPU using Intel Quick Sync Video (QSV) hardware acceleration:\\n\\n:::note\\nThis example assumes that your Proxmox host has an Intel CPU with integrated graphics (with Quick Sync video support) and that you select GPU passthrough in the previous step. If you\'re using a different GPU (e.g., NVIDIA or AMD), you\'ll need to adjust the device mapping and ffmpeg parameters accordingly.\\n:::\\n\\n```bash\\ndocker run --rm -it \\\\\\n  --device /dev/dri:/dev/dri \\\\\\n  -v $(pwd):/data \\\\\\n  linuxserver/ffmpeg \\\\\\n  -y \\\\\\n  -f lavfi -i testsrc=duration=5:size=1280x720:rate=30 \\\\\\n  -f lavfi -i sine=frequency=1000:duration=5 \\\\\\n  -c:v h264_qsv -preset fast -b:v 2M \\\\\\n  -c:a aac -b:a 128k \\\\\\n  -shortest /data/output.mp4\\n\\nls -lh output.mp4\\n```\\n\\nIf everything is set up correctly, you should see the output video file generated in the current directory, copying this back your computer should show that it created a 5 second [test card](https://en.wikipedia.org/wiki/Test_card) video with both video and audio streams.\\n\\nThis quick test shows that rootless Docker is able to access the GPU hardware acceleration from within an unprivileged LXC container and running Jellyfin or Plex should also run correctly.\\n\\n## Forgejo Actions via Docker in Docker (DinD)\\n\\nAnother benefit of using this script allowing unprivileged LXC rootless Docker is that we can now run Docker in Docker (DinD). This allows us to run CI/CD runners such as Forgejo Actions or GitHub Actions runners that can build and run Docker containers as part of their workflows.\\n\\n<details>\\n<summary>Click to expand Git/SSH setup instructions</summary>\\n\\n**As root on the LXC**\\n\\n```bash\\nssh root@192.168...\\napt install acl\\nuseradd --system --create-home git\\n```\\n`/etc/ssh/sshd_config`\\n```ini\\nMatch User git\\n    AuthorizedKeysCommandUser user # <-- replace with non-root user created earlier\\n    AuthorizedKeysCommand /usr/local/bin/forgejo-authorized-keys.sh %u %t %k\\n```\\n`/usr/local/bin/forgejo-authorized-keys.sh`\\n```bash\\n#!/bin/bash\\nset -e\\n\\n/usr/bin/docker exec -i -u git forgejo \\\\\\n  /usr/local/bin/forgejo keys \\\\\\n  --config /var/lib/gitea/custom/conf/app.ini \\\\\\n  -e git \\\\\\n  -u \\"$1\\" \\\\\\n  -t \\"$2\\" \\\\\\n  -k \\"$3\\"\\n```\\n```bash\\nchmod +x /usr/local/bin/forgejo-authorized-keys.sh\\nsystemctl restart sshd\\n```\\n\\n**As non-root user on the LXC**\\n\\n```bash\\nssh user@192.168...\\nsystemctl --user edit docker\\n```\\n```ini\\n[Service]\\nExecStartPost=/usr/bin/setfacl -m u:git:rw %t/docker.sock\\nExecStartPost=/usr/bin/chmod +x %t\\n```\\n```bash\\nsystemctl --user daemon-reload\\nsystemctl --user restart docker\\n```\\n\\n</details>\\n\\n<details>\\n<summary>Click to expand Traefik setup instructions</summary>\\n\\n**As root on the LXC:**\\n\\n`/etc/sysctl.d/99-custom.conf`\\n```conf\\nnet.ipv4.ping_group_range = 0 165535\\nnet.ipv4.ip_unprivileged_port_start = 80\\n```\\n```bash\\nreboot\\n```\\n\\n**As non-root user on the LXC:**\\n\\n`traefik/docker-compose.yml`\\n```yaml\\nservices:\\n  traefik:\\n    # Check migration guide first: https://doc.traefik.io/traefik/v3.6/migrate/v3/\\n    # https://github.com/traefik/traefik/releases\\n    image: docker.io/traefik:v3.6.7\\n    container_name: \'traefik\'\\n    restart: unless-stopped\\n    ports:\\n      - \'80:80\'\\n      - \'443:443\'\\n      # (Optional) Expose Dashboard\\n      # - \'8080:8080\' # Don\'t do this in production!\\n    volumes:\\n      - ./data/config:/etc/traefik:ro\\n      - ./data/certs:/certs\\n      - ./data/plugins:/plugins-local:ro\\n      - ${XDG_RUNTIME_DIR}/docker.sock:/var/run/docker.sock:ro\\n    init: true\\n    healthcheck:\\n      test: wget --quiet --tries=1 --spider http://127.0.0.1/ping || bash -c \'kill -s 15 -1 && (sleep 10; kill -s 9 -1)\'\\n      interval: 30s\\n      timeout: 60s\\n      retries: 3\\n      start_period: 10s\\n    environment:\\n      - LEGO_DISABLE_CNAME_SUPPORT=true\\n    env_file:\\n      - .env\\n    networks:\\n      - \'traefik\'\\n    labels:\\n      traefik.enable: true\\n\\n      traefik.http.routers.traefik-ping.rule: Host(`127.0.0.1`) && Path(`/ping`)\\n      traefik.http.routers.traefik-ping.entrypoints: web\\n      # Override HTTPS redirect\\n      traefik.http.routers.traefik-ping.priority: 2000\\n\\nnetworks:\\n  traefik:\\n    external: true\\n```\\n\\n`traefik/.env`\\n```env\\nDESEC_TOKEN= # Add your deSEC API token\\n```\\n\\nThis example uses deSEC as the provider for Let\'s Encrypt DNS challenges, you can register for a free subdomain and get an API token from your [deSEC account](https://desec.io/) or bring your own domain.\\n\\n`traefik/config/traefik.yml`\\n```yaml\\nentryPoints:\\n  web:\\n    address: :80\\n    # (Optional) Redirect to HTTPS\\n    # ---\\n    http:\\n      redirections:\\n        entryPoint:\\n          to: websecure\\n          scheme: https\\n          priority: 1000\\n\\n  websecure:\\n    address: \\":443\\"\\n    http:\\n      tls:\\n        certResolver: production-desec-dns\\n        domains:\\n          - main: \\"example.dedyn.io\\"\\n            sans:\\n              - \\"*.example.dedyn.io\\"\\n\\nping:\\n  entryPoint: web\\n\\ncertificatesResolvers:\\n  # Staging environment (for testing)\\n  staging-desec-dns:\\n    acme:\\n      dnsChallenge:\\n        provider: desec\\n        propagation:\\n          delayBeforeChecks: 240\\n      email: you@example.com\\n      storage: /certs/acme-letsencrypt-staging-desec-dns.json\\n      caServer: \'https://acme-staging-v02.api.letsencrypt.org/directory\'\\n\\n  # Production (after making sure staging works, as Let\'s Encrypt rate limits failed attempts/restarts)\\n  production-desec-dns:\\n    acme:\\n      dnsChallenge:\\n        provider: desec\\n        propagation:\\n          delayBeforeChecks: 240\\n      email: you@example.com\\n      storage: /certs/acme-letsencrypt-production-desec-dns.json\\n\\nproviders:\\n  docker:\\n    exposedByDefault: false  # Default is true\\n```\\n</details>\\n\\n<details>\\n<summary>Click to expand Forgejo Actions via DinD setup instructions</summary>\\n\\n```bash\\nssh user@192.168...\\nmkdir -p forgejo/runner\\ncd forgejo\\nunshare -rU --map-auto sh -c \\"mkdir data && chown 1000:1000 data\\"\\n```\\n\\n`forgejo/docker-compose.yml`\\n```yaml\\nservices:\\n  forgejo:\\n    # https://codeberg.org/forgejo/forgejo/releases\\n    image: codeberg.org/forgejo/forgejo:14.0.1-rootless\\n    container_name: forgejo\\n    restart: unless-stopped\\n    user: 1000:1000\\n    # ports:\\n    #   - \'3000:3000\'\\n    #   - \'222:2222\'\\n    volumes:\\n      - ./data/var/lib/gitea:/var/lib/gitea\\n      - ./data/etc/gitea:/etc/gitea\\n      - /etc/timezone:/etc/timezone:ro\\n      - /etc/localtime:/etc/localtime:ro\\n    environment:\\n      - USER_UID=1000\\n      - USER_GID=1000\\n      - FORGEJO__actions__ENABLED=true\\n      - FORGEJO__webhook__ALLOWED_HOST_LIST=private,100.64.0.0/10\\n      - FORGEJO__repository.pull-request__DEFAULT_MERGE_STYLE=squash\\n      - FORGEJO__repository__USE_COMPAT_SSH_URI=false\\n      - FORGEJO__server__START_SSH_SERVER=false\\n      - FORGEJO__server__SSH_PORT=22\\n      - FORGEJO__server__SSH_AUTHORIZED_KEYS_COMMAND_TEMPLATE=/usr/bin/docker -H unix://${XDG_RUNTIME_DIR}/docker.sock exec -i -e SSH_ORIGINAL_COMMAND -u git forgejo {{.AppPath}} --config={{.CustomConf}} serv key-{{.Key.ID}}\\n    healthcheck:\\n      test: [\\"CMD\\", \\"curl\\", \\"-f\\", \\"http://localhost:3000/\\"]\\n      interval: 5s\\n      retries: 10\\n      timeout: 5s\\n    networks:\\n      - \\"traefik\\"\\n    labels:\\n      traefik.enable: true\\n      traefik.http.routers.forgejo.entrypoints: web,websecure\\n      traefik.http.routers.forgejo.rule: Host(`forgejo.example.dedyn.io`)\\n      traefik.http.routers.forgejo.tls: true\\n      traefik.http.routers.forgejo.tls.certresolver: production-desec-dns\\n      traefik.http.services.forgejo.loadbalancer.server.port: 3000\\n\\n  dind:\\n    # https://github.com/moby/moby/releases\\n    image: docker:29.1.5-dind\\n    container_name: dind\\n    restart: unless-stopped\\n    privileged: true            # DinD requires privileged (within rootless Docker)\\n    ports:\\n      - \\"2375:2375\\"\\n    environment:\\n      DOCKER_TLS_CERTDIR: \\"\\"    # disable TLS for simplicity internal only\\n    healthcheck:\\n      test: [\\"CMD\\", \\"docker\\", \\"info\\"]\\n      interval: 2s\\n      timeout: 2s\\n      retries: 10\\n    volumes:\\n      - dind-data:/var/lib/docker\\n    networks:\\n      - \\"traefik\\"\\n\\n  runner:\\n    # https://code.forgejo.org/forgejo/runner/releases\\n    image: data.forgejo.org/forgejo/runner:12.6.2\\n    container_name: forgejo-runner\\n    restart: unless-stopped\\n    depends_on:\\n      forgejo:\\n        condition: service_healthy\\n      dind:\\n        condition: service_healthy\\n    environment:\\n      # Point runner to the DinD daemon\\n      DOCKER_HOST: tcp://dind:2375\\n    env_file:\\n      - ./.env-runner\\n    volumes:\\n      - runner-data:/data\\n      - ./data/etc/act_runner:/etc/act_runner\\n      - ./runner/config.yaml:/etc/act_runner/config.yaml\\n    networks:\\n      - \\"traefik\\"\\n    command:\\n      - bash\\n      - -c\\n      - |\\n        if [ ! -f /etc/act_runner/.runner ]; then\\n          pushd /etc/act_runner\\n          forgejo-runner register --no-interactive \\\\\\n            --instance https://forgejo.example.dedyn.io \\\\\\n            --name dind-runner \\\\\\n            --labels docker \\\\\\n            --token \\"$$FORGEJO_RUNNER_REGISTRATION_TOKEN\\"\\n          popd\\n        fi\\n        ln -sf /etc/act_runner/.runner .\\n        forgejo-runner --config /etc/act_runner/config.yaml daemon\\n\\nvolumes:\\n  runner-data:\\n  dind-data:\\n\\nnetworks:\\n  traefik:\\n    external: true\\n```\\n\\n`forgejo/runner/config.yaml`\\n```yaml\\nrunner:\\n  envs:\\n    DOCKER_HOST: tcp://forgejo.example.dedyn.io:2375 # <- replace with your LXC hostname\\n```\\n\\n`forgejo/.env-runner`\\n```bash\\nFORGEJO_RUNNER_REGISTRATION_TOKEN= # Add your Forgejo Actions runner registration token\\n```\\n\\n</details>\\n\\nOnce the files are in place, we can start the Forgejo, Actions, DinD and Traefik services:\\n\\n```bash\\ndocker network create traefik\\ndocker compose -f traefik/docker-compose.yml up -d\\ndocker compose -f forgejo/docker-compose.yml up -d\\n```\\n\\n:::info\\nIt can take take around 5 minutes for HTTPS/TLS certificates to be issued, keep the service running monitoring `docker compose -f traefik/docker-compose.yml logs -f` and check in the `certs` folder, as there will be a new section added to the JSON files under `PrivateKey` with a `Certificates` section once issued.\\n\\nWhen first starting Traefik, it\'s recommended to use the `staging-desec-dns` resolver to avoid hitting Let\'s Encrypt rate limits while testing your setup. Once confirmed working, switch to `production-desec-dns`.\\n:::\\n\\nOnce Traefik and Forgejo are up and running, you should be able to navigate to your Forgejo instance using the URL you set earlier, e.g. `https://forgejo.example.dedyn.io`, and follow the installation wizard.\\n\\nAfter setting up your Forgejo instance, navigate to **Site administration** \u2192 **Actions** \u2192 **Runners** to create a new Action runner and copy the registration token into the `FORGEJO_RUNNER_REGISTRATION_TOKEN` variable in the `forgejo/.env-runner` file and use `docker compose -f forgejo/docker-compose.yml up -d --force-recreate` to pickup the new token and start the runner.\\n\\nCreate a new Access token from **Applications** in your Forgejo account settings, with `issue`, `misc`, `organization`, `package`, and `repository` permissions and add it as a secret named `ACTIONS_TOKEN` under **Actions** \u2192 **Secrets**.\\n\\nNow workflows that use Docker will be able to run inside the unprivileged LXC container using rootless Docker in Docker (DinD).\\n\\n## Conclusion\\n\\nRunning the Docker daemon as `root` or simply granting a user Docker access via the `docker` group creates a large, unnecessary attack surface. I learned this the hard way: a typo in `sudoers` locked me out of one of my servers, and because Docker runs as `root` I was able to mount and fix the file from a container, a capability that should not have been possible.\\n\\n**Why unprivileged LXCs + rootless Docker matters**\\n\\n- Reduced blast radius: compromises are confined to the unprivileged LXC and the non-root user.\\n- Safer CI/runner workflows: enables Docker-in-Docker (DinD) for runners without exposing host-level Docker.\\n- Practical: GPU passthrough and hardware-accelerated workloads still work when configured correctly.\\n\\nFor production and self-hosting deployments, prefer running container engines rootless inside unprivileged LXC containers, as it preserves container convenience while significantly lowering host risk.\\n\\n## Additional resources\\n\\n- [PVE LXC Unprivileged Rootless Docker - pve-unprivileged-lxc-rootless-containers.sh](https://gist.github.com/DigitallyRefined/37dfcc68a146c59e2215c2b5b5fabecc)\\n- [Docker Rootless Mode](https://docs.docker.com/engine/security/rootless/)\\n- [Docker in Docker (DinD)](https://www.docker.com/resources/docker-in-docker-containerized-ci-workflows-dockercon-2023/)\\n- [Proxmox Unprivileged LXC Containers](https://pve.proxmox.com/wiki/Unprivileged_LXC_containers)"},{"id":"/guides/Containers-Up","metadata":{"permalink":"/guides/Containers-Up","editUrl":"https://github.com/DigitallyRefined/DigitallyRefined.github.io/tree/main/blog/2026-01-31-Containers-Up.mdx","source":"@site/blog/2026-01-31-Containers-Up.mdx","title":"Containers Up!","description":"Containers Up! is an open source web-based container management platform designed to simplify the administration of containers across multiple remote hosts.","date":"2026-01-31T00:00:00.000Z","tags":[{"inline":true,"label":"Tunnelling","permalink":"/tags/tunnelling"},{"inline":true,"label":"Self-hosting","permalink":"/tags/self-hosting"},{"inline":true,"label":"Docker","permalink":"/tags/docker"},{"inline":true,"label":"YouTube","permalink":"/tags/you-tube"},{"inline":true,"label":"Video","permalink":"/tags/video"}],"readingTime":12.65,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"/guides/Containers-Up","tags":["Tunnelling","Self-hosting","Docker","YouTube","Video"],"last_update":{"date":"2026-02-02T00:00:00.000Z"}},"unlisted":false,"lastUpdatedAt":1769990400000,"prevItem":{"title":"Running rootless Docker on a Proxmox unprivileged LXC","permalink":"/guides/PVE-unprivileged-LXC-rootless-containers"},"nextItem":{"title":"Everything Presence Lite sensor","permalink":"/guides/Everything-Presence-Lite-sensor"}},"content":"[Containers Up!](https://github.com/DigitallyRefined/containers-up) is an open source web-based container management platform designed to simplify the administration of containers across multiple remote hosts.\\n\\nIt provides a unified interface for managing containerized applications, and automating updates with minimal manual intervention.\\n\\nThis guide will step through setting up your own instance of Containers Up! and configuring Dependabot on GitHub or Renovate Bot with Forgejo.\\n\\n{/* truncate */}\\n\\nimport TOCInline from \'@theme/TOCInline\';\\n\\n<TOCInline toc={toc} />\\n\\n## Video\\n\\nimport LiteYouTubeEmbed from \'react-lite-youtube-embed\';\\nimport \'react-lite-youtube-embed/dist/LiteYouTubeEmbed.css\';\\n\\n<LiteYouTubeEmbed\\n  id=\\"BXh_dP7b07k\\"\\n  title=\\"Containers Up! - A stable way to manage container updates\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n<a href=\\"https://youtu.be/BXh_dP7b07k\\">Watch on YouTube</a>\\n\\n## Installation\\n\\n### Prerequisites\\n\\nBefore getting started, you\'ll need:\\n\\n- A server or mini PC with Docker installed\\n- SSH access to your server\\n- (Optional) A domain name with HTTPS configured via [Traefik](https://doc.traefik.io/traefik/) or similar reverse proxy ([deSEC](https://desec.io/) is a good way to test HTTPS with free subdomain and wildcard certificates)\\n- (Optional) A Git repository (GitHub or Forgejo) for automated updates\\n- (Optional) A VPS or tunnelling solution to expose your webhook port securely ([AWS](https://aws.amazon.com/free/) & [Oracle Cloud](https://www.oracle.com/cloud/free/) both have free VPS tiers to test this setup)\\n\\n### Basic Setup\\n\\nThe simplest way to get started is with the following `compose.yml`:\\n\\n```yaml\\nservices:\\n  containers-up:\\n    # https://github.com/DigitallyRefined/containers-up/releases\\n    image: ghcr.io/digitallyrefined/containers-up:1.4.5\\n    restart: unless-stopped\\n    ports:\\n      - 3000:3000 # Main dashboard\\n      - 3001:3001 # Webhook port\\n    volumes:\\n      - ./storage:/storage\\n      - ./storage/.ssh:/root/.ssh\\n      - ./storage/.docker:/root/.docker\\n```\\n\\n:::info\\nSee the [Containers Up! GitHub repository](https://github.com/DigitallyRefined/containers-up) for the latest release tag.\\n:::\\n\\n1. Create a directory for Containers Up!: `mkdir containers-up && cd containers-up`\\n2. Save the above compose file\\n3. Start the service: `docker compose up -d`\\n4. Open `http://localhost:3000` in your browser\\n\\n### Adding Your First Host\\n\\n#### Creating a separate SSH Key for the app to use\\n\\nIdeally you should create an SSH key pair specifically for Containers Up! to use:\\n\\n```bash\\nssh-keygen -t ed25519 -C \\"containers-up\\" -f ~/.ssh/containers-up\\n```\\n\\nThen add the public key to your server\'s `~/.ssh/authorized_keys`:\\n\\n```bash\\ncat ~/.ssh/containers-up.pub | ssh user@yourhost \'cat >> ~/.ssh/authorized_keys\'\\n```\\n\\n#### Adding the Host in Containers Up!\\n\\nWhen you first access the dashboard, you\'ll need to add a host:\\n\\n1. Click **Add Host** in the UI\\n2. Fill in the following required fields:\\n   - **Name**: A unique identifier (e.g., `my-server`) - lowercase letters, numbers, and hyphens only\\n   - **SSH Host**: Your server\'s SSH connection string in the format `user@hostname` or `user@ip-address`\\n   - **SSH Private Key**: Paste your SSH private key (must be in OpenSSH format)\\n\\n3. **Optional fields** for automation:\\n   - **Working Folder**: Path to your compose files on the remote host (e.g., `/home/user/stacks`)\\n   - **Repository Host**: Git provider URL (default: `https://github.com`)\\n   - **Repository**: Your repo in format `username/repo`\\n   - **Bot Type**: Choose `dependabot` (GitHub) or `renovate` (Forgejo)\\n   - **Webhook Secret**: Generate a random secret for webhook authentication\\n   - **Exclude Folders**: Regex pattern to exclude certain folders (e.g., `(manual|test)`)\\n   - **Cron Schedule**: When to check for image updates (e.g., `0 1 * * 6` for Saturdays at 1 AM)\\n   - **Squash Updates**: Enable to automatically combine multiple dependency update commits\\n\\n4. Click **Save** - the system will validate your SSH connection and Docker availability\\n\\nOnce added, you\'ll see a dashboard showing:\\n\\n- **Composed Containers**: Services managed via compose files\\n- **Individual Containers**: Standalone containers\\n- **Images**: All Docker images on the host\\n- **Unused Images**: Images that can be cleaned up\\n\\n<details>\\n<summary>**Setup with HTTPS & Authentication (optional, but recommended!)**</summary>\\n\\nFor production deployments with secure HTTPS access and authentication, you can use Traefik as a reverse proxy with Pocket ID for OpenID Connect authentication.\\n\\n#### Traefik Certificate Resolver Configuration\\n\\nBefore deploying, you\'ll need to configure Traefik\'s certificate resolver for automatic HTTPS certificates. Create or update your Traefik configuration file at `./traefik/config/traefik.yml`:\\n\\n**Setting up deSEC DNS Challenge:**\\n\\nThis example uses [deSEC](https://desec.io/) for a free subdomain and DNS challenge to obtain wildcard certificates, but you can also use other providers such as Cloudflare.\\n\\nIf using the `production-desec-dns` resolver, you\'ll need to provide your deSEC API token to Traefik:\\n\\n1. Sign up for a free account at [deSEC.io](https://desec.io/) and create a domain\\n2. Generate an API token in your deSEC dashboard\\n3. Create a `.env` file in the same directory as your `compose.yml`:\\n\\n   ```bash\\n   # deSEC API Token for Traefik DNS Challenge\\n   DESEC_TOKEN=your_desec_api_token_goes_here\\n   ```\\n\\n4. Update your Traefik service in `compose.yml` to use the `.env` file:\\n\\n   ```yaml\\n   traefik:\\n     image: traefik:v...\\n     # ... other settings ...\\n     env_file:\\n       - ./.env\\n   ```\\n\\n5. Make sure to add `.env` to your `.gitignore` to avoid committing sensitive tokens\\n\\n<details>\\n<summary>Click to expand Traefik certificate resolver configuration</summary>\\n\\n```yaml\\ncertificatesResolvers:\\n  # Staging environment (for testing)\\n  staging-desec-dns:\\n    acme:\\n      dnsChallenge:\\n        provider: desec\\n      propagation:\\n        delayBeforeChecks: 240\\n      email: you@example.com\\n      storage: /certs/acme-letsencrypt-staging-desec-dns.json\\n      caServer: \'https://acme-staging-v02.api.letsencrypt.org/directory\'\\n\\n  # Production (after making sure staging works, as Let\'s Encrypt rate limits failed attempts/restarts)\\n  production-desec-dns:\\n    acme:\\n      dnsChallenge:\\n        provider: desec\\n      propagation:\\n        delayBeforeChecks: 240\\n      email: you@example.com\\n      storage: /certs/acme-letsencrypt-production-desec-dns.json\\n```\\n\\n</details>\\n\\n#### Complete Setup Example\\n\\n<details>\\n<summary>Click to expand complete `compose.yml` with all three services</summary>\\n\\n```yaml\\nservices:\\n  containers-up:\\n    # https://github.com/DigitallyRefined/containers-up/releases\\n    image: ghcr.io/digitallyrefined/containers-up:1.4.5\\n    restart: unless-stopped\\n    volumes:\\n      - ./containers-up/storage:/storage\\n      - ./containers-up/storage/.ssh:/root/.ssh\\n      - ./containers-up/storage/.docker:/root/.docker\\n    env_file:\\n      - ./.env # Create this file based on .env.default\\n    networks:\\n      - traefik\\n    labels:\\n      traefik.enable: true\\n\\n      # Main dashboard (requires authentication)\\n      traefik.http.routers.containers-up.entrypoints: websecure\\n      traefik.http.routers.containers-up.rule: Host(`containers-up.example.dedyn.io`)\\n      traefik.http.routers.containers-up.tls: true\\n      traefik.http.routers.containers-up.tls.certresolver: production-desec-dns\\n      traefik.http.routers.containers-up.service: containers-up\\n      traefik.http.services.containers-up.loadbalancer.server.port: 3000\\n\\n      # Webhook endpoint (public access for GitHub/Forgejo webhooks)\\n      traefik.http.routers.containers-up-webhook.entrypoints: websecure\\n      traefik.http.routers.containers-up-webhook.rule: Host(`containers-up.example.dedyn.io`) && PathPrefix(`/api/webhook`)\\n      traefik.http.routers.containers-up-webhook.tls: true\\n      traefik.http.routers.containers-up-webhook.tls.certresolver: production-desec-dns\\n      traefik.http.routers.containers-up-webhook.service: containers-up-webhook\\n      traefik.http.services.containers-up-webhook.loadbalancer.server.port: 3001\\n\\n  pocket-id:\\n    # https://github.com/pocket-id/pocket-id/releases\\n    image: ghcr.io/pocket-id/pocket-id:v2.2.0\\n    restart: unless-stopped\\n    volumes:\\n      - \'./pocket-id/data:/app/data\'\\n    environment:\\n      - APP_URL=https://id.example.dedyn.io\\n      - TRUST_PROXY=true\\n      - ENCRYPTION_KEY=\\"run `openssl rand -base64 32`\\" # Generate a unique key\\n    networks:\\n      - \'traefik\'\\n    labels:\\n      traefik.enable: true\\n      traefik.http.routers.pocketid.entrypoints: websecure\\n      traefik.http.routers.pocketid.rule: Host(`id.example.dedyn.io`)\\n      traefik.http.routers.pocketid.tls: true\\n      traefik.http.routers.pocketid.tls.certresolver: production-desec-dns\\n\\n  traefik:\\n    # https://github.com/traefik/traefik/releases\\n    image: traefik:v3.6.7\\n    container_name: \'traefik\'\\n    restart: unless-stopped\\n    ports:\\n      - \'80:80\'\\n      - \'443:443\'\\n    environment:\\n      - LEGO_DISABLE_CNAME_SUPPORT=true\\n    volumes:\\n      - ./traefik/config:/etc/traefik\\n      - /var/run/docker.sock:/var/run/docker.sock:ro\\n    networks:\\n      - \'traefik\'\\n\\nnetworks:\\n  traefik:\\n    external: true\\n```\\n\\n:::info\\nIt can take take around 5 minutes for certificates to be issued, keep the service running monitoring `docker compose logs -f` and check in the `certs` folder, as there will be a new section added to the JSON files under `PrivateKey` with a `Certificates` section once issued.\\n\\nWhen first starting Traefik, it\'s recommended to use the `staging-desec-dns` resolver to avoid hitting Let\'s Encrypt rate limits while testing your setup. Once confirmed working, switch to `production-desec-dns`.\\n:::\\n\\n</details>\\n\\n**Notes:**\\n\\n- Replace `you@example.com` with your actual email address\\n- The `production-desec-dns` resolver uses DNS challenge with [deSEC](https://desec.io/) provider (free DNS service with API support)\\n- DNS challenge is recommended for wildcard certificates or when port 80 is not accessible\\n- The `storage` path must match a volume mounted in your Traefik container (e.g., `./traefik/certs:/certs`)\\n\\nSee the [Traefik ACME documentation](https://doc.traefik.io/traefik/https/acme/) for more certificate resolver options.\\n\\n#### Setup Steps\\n\\n1. **Update domains** in the compose file:\\n   - Replace `containers-up.example.dedyn.io` with your Containers Up! domain\\n   - Replace `id.example.dedyn.io` with your Pocket ID domain\\n\\n2. **Generate encryption key** for Pocket ID:\\n\\n   ```bash\\n   openssl rand -base64 32\\n   ```\\n\\n3. **Create the network and start services**:\\n\\n   ```bash\\n   docker network create traefik\\n   docker compose up -d\\n   ```\\n\\n4. **Configure Pocket ID**:\\n   - Navigate to your Pocket ID instance (`https://id.example.dedyn.io`)\\n   - Follow the [Pocket ID setup guide](https://pocket-id.org/docs/setup/installation) to create an admin user\\n   - Optionally create an admin group and add your user to it\\n\\n5. **Create OIDC Client in Pocket ID**:\\n   - In Pocket ID admin, create a new OIDC client\\n   - Set the callback URL to: `https://containers-up.example.dedyn.io/auth-callback`\\n   - Optionally restrict access to the admin group only\\n   - Copy the **Client ID** and **Client Secret**\\n\\n6. **Configure Containers Up! OIDC**:\\n\\n   Create a `.env` file with the following OIDC configuration:\\n\\n   ```bash\\n   # OpenID Connect Authentication\\n   ENV_PUBLIC_OIDC_ISSUER_URI=https://id.example.dedyn.io\\n   ENV_PUBLIC_OIDC_CLIENT_ID=your_client_id_here\\n   OIDC_CLIENT_SECRET=your_client_secret_here\\n   # OIDC_JWKS_URL=https://id.example.dedyn.io/.well-known/jwks.json  # Optional: only needed if auto-discovery fails\\n   ```\\n\\n7. **Restart Containers Up!**:\\n\\n   ```bash\\n   docker compose restart containers-up\\n   ```\\n\\n8. **Test authentication**:\\n   - Navigate to `https://containers-up.example.dedyn.io`\\n   - You should be redirected to Pocket ID for login\\n   - After successful login, you\'ll be redirected back to Containers Up!\\n\\n#### Notes\\n\\n- The **main dashboard** (port 3000) is protected by OIDC authentication\\n- The **webhook endpoint** (port 3001) remains publicly accessible but is secured by webhook signature verification\\n- Make sure your `.env` file is not committed to Git (add it to `.gitignore`)\\n- See the [Pocket ID documentation](https://pocket-id.org) for advanced configuration options\\n</details>\\n\\n### Environment Variables\\n\\nOptional configuration such as authentication and notifications can be set via a `.env` file:\\n\\n```yaml\\nservices:\\n  containers-up:\\n    image: ghcr.io/digitallyrefined/containers-up:1.4.5\\n    # ... other settings ...\\n    env_file:\\n      - ./.env\\n```\\n\\nSee the full list in the [repository\'s `.env.default`](https://github.com/DigitallyRefined/containers-up/blob/main/.env.default) file.\\n\\n## Setting Up Automated Updates\\n\\nOne of Containers Up!\'s most powerful features is automated container updates via Git-based workflows. This section covers setting up Dependabot (GitHub) or Renovate (Forgejo) to automatically create pull requests when new container images are available.\\n\\n### Prerequisites for Automation\\n\\nBefore configuring automated updates:\\n\\n1. Your Containers Up! instance must be **publicly accessible via HTTPS** on port `3001` (webhook port)\\n   - You can use [Cloudflare Tunnels](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/), [Pangolin](https://pangolin.net/), [Docker WireGuard Tunnel](https://github.com/DigitallyRefined/docker-wireguard-tunnel), or see [Awesome Tunnelling](https://github.com/anderspitman/awesome-tunneling) for even more options\\n\\n2. Create a Git repository with your `compose.yml` or `docker-compose.yml` files\\n\\n3. **Pin all image versions** - replace `:latest` tags with specific versions:\\n\\n   ```yaml\\n   # \u274c Don\'t use this\\n   image: traefik\\n\\n   # \u274c Or this\\n   image: traefik:latest\\n\\n   # \u2705 Use specific versions\\n   image: traefik:v3.6.7\\n   ```\\n\\n### Option A: GitHub with Dependabot\\n\\n#### 1. Enable GitHub Actions\\n\\nIn your repository **Settings > Actions > General**:\\n\\n- Enable **Allow all actions and reusable workflows**\\n- Under **Workflow permissions**, allow **Read and write permissions**\\n- Allow **GitHub Actions to create and approve pull requests**\\n\\n#### 2. Create Dependabot Template\\n\\nCreate `.github/dependabot.template.yml`:\\n\\n```yaml\\nversion: 2\\nenable-beta-ecosystems: true # Remove once docker-compose updates become stable\\nupdates:\\n  - package-ecosystem: \'docker-compose\'\\n    directory: \'**/docker-compose.yml\'\\n    schedule:\\n      interval: \'weekly\'\\n      day: \'saturday\'\\n      time: \'01:23\'\\n      timezone: \'Europe/London\' # <-- Change to your timezone\\n\\n  - package-ecosystem: \'github-actions\'\\n    directory: \'/\'\\n    schedule:\\n      interval: \'weekly\'\\n      day: \'saturday\'\\n      time: \'01:23\'\\n      timezone: \'Europe/London\' # <-- Change to your timezone\\n```\\n\\n#### 3. Add GitHub Action to Generate Dependabot Config\\n\\nCreate `.github/workflows/generate_dependabot.yml`:\\n\\n```yaml\\nname: Generate dependabot.yml\\n\\non:\\n  push:\\n    branches:\\n      - main\\n  repository_dispatch:\\n  workflow_dispatch:\\n\\njobs:\\n  generate:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v6\\n\\n      - name: Generate dependabot.yml\\n        uses: Makeshift/generate-dependabot-glob-action@master\\n\\n      - name: Create Pull Request\\n        uses: peter-evans/create-pull-request@v8\\n```\\n\\nThis workflow will automatically create a managed `.github/dependabot.yml` file that updates as you add new compose files.\\n\\n#### 4. Configure Webhook in Containers Up!\\n\\nIn the Containers Up! dashboard:\\n\\n1. Edit your host configuration\\n2. Set the **Working Folder** (e.g., `/home/user/stacks`)\\n3. Set **Repository** to `username/repo`\\n4. Generate a random **Webhook Secret** (e.g., using `openssl rand -hex 32`)\\n5. Click the \u2139\ufe0f icon to view your webhook URL (will look like: `https://containers-up.example.dedyn.io/api/webhook/github/host/YOUR_HOST`)\\n6. Save the host configuration\\n\\n#### 5. Configure GitHub Webhook\\n\\nIn your GitHub repository **Settings > Webhooks > Add webhook**:\\n\\n1. **Payload URL**: Your webhook URL from step 4\\n2. **Content type**: `application/json`\\n3. **Secret**: The same webhook secret from Containers Up!\\n4. **Events**: Select **Let me select individual events** and choose **Pull requests**\\n5. Click **Add webhook**\\n\\nTest it by clicking the webhook and selecting **Recent Deliveries > Redeliver**. You should see a \\"ping\\" event in the Containers Up! logs.\\n\\n### Option B: Forgejo with Renovate Bot\\n\\n#### 1. Create Access Tokens\\n\\nIn Forgejo **Settings > Application**:\\n\\n1. Create an **Access Token** with the permissions listed in the [Renovate Forgejo docs](https://docs.renovatebot.com/modules/platform/forgejo/)\\n2. In **Actions > Secrets**:\\n   - Create `ACTIONS_TOKEN` with your Forgejo token\\n   - Create `EXTERNAL_GITHUB_TOKEN` with a GitHub Personal Access Token (for fetching changelogs)\\n\\n#### 2. Create Renovate Workflow\\n\\n<details>\\n<summary>Click to expand `.forgejo/workflows/renovate.yml`</summary>\\n\\n```yaml\\nname: Renovate\\n\\non:\\n  push:\\n    branches:\\n      - main\\n      - \'renovate/**\'\\n  schedule:\\n    # At 02:00, only on Saturday\\n    - cron: \'0 2 * * 6\'\\n  issues:\\n    types:\\n      - edited\\n  workflow_dispatch: # Allow manual trigger\\n\\njobs:\\n  renovate:\\n    runs-on: docker\\n    container:\\n      image: renovate/renovate:43.0.6\\n\\n    steps:\\n      - name: Restore Renovate Cache\\n        uses: actions/cache@v5\\n        with:\\n          path: ${{ github.workspace }}/renovate-cache\\n          key: renovate-cache-${{ runner.os }}\\n          restore-keys: |\\n            renovate-cache-\\n\\n      - name: Set Git identity\\n        run: |\\n          git config --global user.name \\"Renovate Bot\\"\\n          git config --global user.email \\"renovate@localhost\\"\\n\\n      - name: Run Renovate\\n        env:\\n          LOG_LEVEL: info\\n          RENOVATE_PLATFORM: forgejo\\n          RENOVATE_ENDPOINT: ${{ github.api_url }} # GitHub variables still work in Forgejo\\n          RENOVATE_TOKEN: ${{ secrets.ACTIONS_TOKEN }}\\n          RENOVATE_REPOSITORIES: ${{ github.repository }}\\n          RENOVATE_GITHUB_COM_TOKEN: ${{ secrets.EXTERNAL_GITHUB_TOKEN }}\\n          RENOVATE_CACHE_DIR: ${{ github.workspace }}/renovate-cache\\n        run: renovate\\n```\\n\\n</details>\\n\\n#### 3. Configure Webhook in Containers Up!\\n\\nSimilar to GitHub setup:\\n\\n1. Edit your host, set **Bot Type** to `renovate`\\n2. Set **Working Folder**, **Repository** (`username/repo`)\\n3. Set **Repository Host** to your Forgejo URL (e.g., `https://git.example.dedyn.io`)\\n4. Generate a **Webhook Secret**\\n5. Note the webhook URL (will include `/forgejo/` in the path)\\n\\n#### 4. Configure Forgejo Webhook\\n\\nIn your Forgejo repository **Settings > Webhooks > Add Forgejo webhook**:\\n\\n1. **Target URL**: Your webhook URL\\n2. **HTTP Method**: `POST`\\n3. **Content Type**: `application/json`\\n4. **Secret**: Your webhook secret\\n5. **Trigger On**: **Custom events > Pull request modifications**\\n\\n### How It Works\\n\\nOnce configured, the workflow is:\\n\\n1. **Dependabot/Renovate** scans your compose files weekly (or on your schedule)\\n2. When a new image version is found, a **Pull Request** is created\\n3. The PR triggers a **webhook** to Containers Up!\\n4. Containers Up! displays the update in the dashboard with a notification\\n5. You **review the changelog** and decide whether to merge\\n6. When merged, another webhook triggers Containers Up! to:\\n   - Pull the updated compose file from Git\\n   - Pull the new Docker image\\n   - Restart the containers with the new image\\n\\n### Optional: Commit Squashing\\n\\nIf you enable **Squash Updates** in your host configuration, Containers Up! will automatically combine multiple dependency update commits to keep your Git history clean. This is useful when multiple PRs are merged in quick succession.\\n\\nThe squashing behavior can be customised with environment variables:\\n\\n- `SQUASH_UPDATE_MESSAGE`: Commit message prefix (default: `Update dependencies`)\\n- `SQUASH_DAYS_AGO`: Number of days before considering a commit too old to squash with newer dependency updates (default: `5` days)\\n- `SQUASH_MAX_UPDATE_COMMITS`: Maximum number of dependency update commits to keep before squashing the oldest two together (default: `5`)\\n\\n## Additional resources\\n\\n<LiteYouTubeEmbed\\n  id=\\"c8f-YPiUBZM\\"\\n  title=\\"Self-hosted Cloudflare + VPN replacement! Pangolin Tutorial\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n- <a href=\\"https://youtu.be/c8f-YPiUBZM\\">\\n    Self-hosted Cloudflare + VPN replacement! Pangolin Tutorial\\n  </a>\\n\\n<LiteYouTubeEmbed\\n  id=\\"GKyMXguNcos\\"\\n  title=\\"DITCH PASSWORDS: Self-Host PassKeys with Pocket ID\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n- <a href=\\"https://youtu.be/GKyMXguNcos\\">\\n    DITCH PASSWORDS: Self-Host PassKeys with Pocket ID\\n  </a>\\n\\n<LiteYouTubeEmbed\\n  id=\\"-hfejNXqOzA\\"\\n  title=\\"Simple HTTPs for Docker! // Traefik Tutorial (updated)\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n- <a href=\\"https://youtu.be/-hfejNXqOzA\\">\\n    Simple HTTPs for Docker! // Traefik Tutorial (updated)\\n  </a>"},{"id":"/guides/Everything-Presence-Lite-sensor","metadata":{"permalink":"/guides/Everything-Presence-Lite-sensor","editUrl":"https://github.com/DigitallyRefined/DigitallyRefined.github.io/tree/main/blog/2023-11-06-Everything-Presence-Lite-sensor.mdx","source":"@site/blog/2023-11-06-Everything-Presence-Lite-sensor.mdx","title":"Everything Presence Lite sensor","description":"The Everything Presence Lite sensor was release in October 2023 for \xa328 or around $30 (plus postage) from Everything Smart Technology.","date":"2023-11-06T00:00:00.000Z","tags":[{"inline":true,"label":"Reviews","permalink":"/tags/reviews"},{"inline":true,"label":"Home Assistant","permalink":"/tags/home-assistant"},{"inline":true,"label":"Smart Home","permalink":"/tags/smart-home"},{"inline":true,"label":"Hardware","permalink":"/tags/hardware"},{"inline":true,"label":"ESP32","permalink":"/tags/esp-32"},{"inline":true,"label":"Automations","permalink":"/tags/automations"},{"inline":true,"label":"YouTube","permalink":"/tags/you-tube"},{"inline":true,"label":"Video","permalink":"/tags/video"}],"readingTime":3.15,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"/guides/Everything-Presence-Lite-sensor","tags":["Reviews","Home Assistant","Smart Home","Hardware","ESP32","Automations","YouTube","Video"],"last_update":{"date":"2023-11-07T00:00:00.000Z"}},"unlisted":false,"lastUpdatedAt":1699315200000,"prevItem":{"title":"Containers Up!","permalink":"/guides/Containers-Up"},"nextItem":{"title":"Tailscale & Headscale","permalink":"/guides/Tailscale-Headscale-setup"}},"content":"The [Everything Presence Lite](https://shop.everythingsmart.io/products/everything-presence-lite) sensor was release in October 2023 for \xa328 or around $30 (plus postage) from [Everything Smart Technology](https://shop.everythingsmart.io).\\n\\n{/* truncate */}\\n\\nimport TOCInline from \'@theme/TOCInline\';\\n\\n<TOCInline toc={toc} />\\n\\n## Video\\n\\nimport LiteYouTubeEmbed from \'react-lite-youtube-embed\';\\nimport \'react-lite-youtube-embed/dist/LiteYouTubeEmbed.css\'\\n\\n<LiteYouTubeEmbed\\n  id=\\"HABmLjZ2mWQ\\"\\n  title=\\"Everything Presence Lite sensor - Quick look, unboxing and setup\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n<a href=\\"https://youtu.be/HABmLjZ2mWQ\\">Watch on YouTube</a>\\n\\n## Features\\n\\n* Precise mmWave radar motion detector\\n* Light luminosity (or room brightness) sensor\\n* WiFi\\n* Bluetooth repeater/Home Assistant proxy\\n* ESP32 (can be extended using GPIO pins)\\n* 3D printed case\\n* USB-C\\n\\n## Pros\\n\\n* Relatively inexpensive way to add presence, motion and room brightness data to your smart home\\n* Much more sensitive than a regular PIR motion sensor and can easily detect people that are sitting still\\n* Can perform automatons based on sensor data, such as turning on/off lights\\n* Beta zones feature can perform different actions/automations based on where the motion/presence was detected\\n* Can see through thin walls\\n* Can extend your Home Assistant Bluetooth range via proxy\\n* Good quality braided cable\\n* Works with Home Assistant via WiFi\\n* USB-C powered\\n\\n## Cons\\n\\n* Not always in stock since they\'re a relative small startup business\\n* Setting up different zones can be tricky, as it\'s a beta feature requiring trial and error defining coordinates in 3D space by using start and end X/Y millimetre values\\n* It\'s capable of detecting small movements such as breathing, however I was able to sit still long enough for it to give me a false positive and detect me as away (though sensitivity can be calibrated, to fix this)\\n* Only available in white\\n\\n## Home Assistant automations\\n\\nNote: you\'ll need to paste this in YAML mode then switch back to the visual editor you should then be able to update the device/light IDs.\\n\\n### On - Lights on when dark & presence detected\\n\\n```yml\\nalias: On - Lights on when dark & presence detected\\ndescription: \\"\\"\\ntrigger:\\n  - platform: sun\\n    event: sunset\\n    offset: \\"-00:30:00\\"\\n  - type: illuminance\\n    platform: device\\n    entity_id: sensor.epl_presence_illuminance\\n    domain: sensor\\n    for:\\n      hours: 0\\n      minutes: 0\\n      seconds: 20\\n    below: 2.7\\n  - platform: state\\n    entity_id:\\n      - binary_sensor.epl_presence_occupancy\\n    to: \\"on\\"\\n  - platform: state\\n    entity_id:\\n      - person.DigitallyRefined\\n    from: not_home\\n    to: home\\ncondition:\\n  - condition: time\\n    before: \\"21:55:00\\"\\n  - condition: device\\n    type: is_off\\n    device_id: <pick your light>\\n    domain: light\\n  - condition: or\\n    conditions:\\n      - type: is_illuminance\\n        condition: device\\n        entity_id: sensor.epl_presence_illuminance\\n        domain: sensor\\n        below: 2.7\\n      - condition: sun\\n        after: sunset\\n        after_offset: \\"-00:30:00\\"\\n  - condition: numeric_state\\n    entity_id: zone.home\\n    above: 0\\n  - condition: state\\n    entity_id: binary_sensor.epl_presence_occupancy\\n    state: \\"on\\"\\n  # Optional condition based on a Zigbee button press to prevent lights from automatically turning on again\\n  # (within 1 hour when they have been manually be turned off)\\n  - condition: template\\n    value_template: >-\\n      {{ ((as_timestamp(now()) -\\n      as_timestamp(states.scene.lights_off_manually_triggered.state)) > 3600) or\\n      (as_timestamp(states.scene.lights_on.state) >\\n      as_timestamp(states.scene.lights_off_manually_triggered.state)) }}\\naction:\\n  - service: scene.turn_on\\n    target:\\n      entity_id: scene.lights_on\\n    metadata: {}\\nmode: single\\n```\\n\\n### Off - Lights (no occupancy)\\n\\n```yaml\\nalias: Off - Lights (no occupancy)\\ndescription: \\"\\"\\ntrigger:\\n  - platform: state\\n    entity_id:\\n      - binary_sensor.epl_presence_occupancy\\n    from: \\"on\\"\\n    to: \\"off\\"\\ncondition:\\n  - condition: device\\n    type: is_on\\n    device_id: <pick your light>\\n    domain: switch\\n  # Optional condition to check if a Smart TV is not current being used\\n  - condition: not\\n    conditions:\\n      - condition: device\\n        domain: media_player\\n        entity_id: <pick your Android TV or streaming device>\\n        type: is_playing\\naction:\\n  - service: script.slowly_turn_off_lights_no_occupancy\\n    data: {}\\nmode: single\\n```\\n\\n## Home Assistant scripts\\n\\n### Off - Slowly turn off lights (no occupancy)\\n\\n```yaml\\nalias: Off - Slowly turn off lights (no occupancy)\\nsequence:\\n  - if:\\n      - condition: state\\n        entity_id: binary_sensor.epl_presence_occupancy\\n        state: \\"off\\"\\n    then:\\n      - type: turn_off\\n        entity_id: <choose first light>\\n        domain: light\\n      - delay:\\n          hours: 0\\n          minutes: 0\\n          seconds: 10\\n          milliseconds: 0\\n      - if:\\n          - condition: state\\n            entity_id: binary_sensor.epl_presence_occupancy\\n            state: \\"off\\"\\n        then:\\n          - type: turn_off\\n            entity_id: <choose second light>\\n            domain: light\\n          - delay:\\n              hours: 0\\n              minutes: 0\\n              seconds: 10\\n              milliseconds: 0\\n          - if:\\n              - condition: state\\n                entity_id: binary_sensor.epl_presence_occupancy\\n                state: \\"off\\"\\n            then:\\n              - type: turn_off\\n                entity_id: <choose third light etc...>\\n                domain: switch\\nmode: single\\nicon: mdi:lightbulb-multiple-off-outline\\n```"},{"id":"/guides/Tailscale-Headscale-setup","metadata":{"permalink":"/guides/Tailscale-Headscale-setup","editUrl":"https://github.com/DigitallyRefined/DigitallyRefined.github.io/tree/main/blog/2023-06-01-Tailscale-Headscale-setup.mdx","source":"@site/blog/2023-06-01-Tailscale-Headscale-setup.mdx","title":"Tailscale & Headscale","description":"Setting up your own self hosted remote access","date":"2023-06-01T00:00:00.000Z","tags":[{"inline":true,"label":"Tailscale","permalink":"/tags/tailscale"},{"inline":true,"label":"VPN","permalink":"/tags/vpn"},{"inline":true,"label":"Tunnelling","permalink":"/tags/tunnelling"},{"inline":true,"label":"Self-hosting","permalink":"/tags/self-hosting"},{"inline":true,"label":"Docker","permalink":"/tags/docker"},{"inline":true,"label":"YouTube","permalink":"/tags/you-tube"},{"inline":true,"label":"Video","permalink":"/tags/video"}],"readingTime":6.37,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"/guides/Tailscale-Headscale-setup","tags":["Tailscale","VPN","Tunnelling","Self-hosting","Docker","YouTube","Video"],"last_update":{"date":"2024-05-19T00:00:00.000Z"}},"unlisted":false,"lastUpdatedAt":1716076800000,"prevItem":{"title":"Everything Presence Lite sensor","permalink":"/guides/Everything-Presence-Lite-sensor"},"nextItem":{"title":"IKEA VINDSTYRKA","permalink":"/guides/IKEA-VINDSTYRKA"}},"content":"## Setting up your own self hosted remote access\\n\\n[Headscale](https://headscale.net/) is an open source implementation of the [Tailscale](https://tailscale.com/) coordination server.\\n\\nThis guide will step through setting up your own self hosted private and secure remote access using Tailscale clients along with a self hosted Headscale Docker container.\\n\\n{/* truncate */}\\n\\n:::warning\\n\\nMentions of this being a free service in the video below are now no longer correct:\\n\\n* To launch a server, a credit card is now required  (a temporary charge between $1-$10 will be taken to verify it)\\n* Fly.io no longer offer free [dedicated IPv4 addresses](https://fly.io/docs/about/pricing/#anycast-ip-addresses), these are now charged at $2/month for each IPv4 address.\\n* Fly.io gives new accounts [$5 of free trial credit and Hobby plans cost $5 per month](https://fly.io/docs/about/pricing/#new-customers-get-a-free-trial).\\n\\nSo in theory as long as you don\'t exceed the $5 free trial credit, this setup should still be free. Make sure that you check [their current free allowances](https://fly.io/docs/about/pricing/#free-allowances), as they may have changed since this guide was last published.\\n\\n:::\\n\\nimport TOCInline from \'@theme/TOCInline\';\\n\\n<TOCInline toc={toc} />\\n\\n## Video\\n\\nimport LiteYouTubeEmbed from \'react-lite-youtube-embed\';\\nimport \'react-lite-youtube-embed/dist/LiteYouTubeEmbed.css\'\\n\\n<LiteYouTubeEmbed\\n  id=\\"rGJ5RvB_aBg\\"\\n  title=\\"Tailscale & Headscale - Setting up your own self hosted remote access\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n<a href=\\"https://youtu.be/rGJ5RvB_aBg\\">Watch on YouTube</a>\\n\\n## Installation\\n\\n### Fly.io client\\n\\n```bash\\nsudo apt install curl\\ncurl -L https://fly.io/install.sh | sh\\n```\\n\\n```bash\\necho \'export FLYCTL_INSTALL=\\"$HOME/.fly\\"\' >> ~/.bashrc\\necho \'export PATH=\\"$FLYCTL_INSTALL/bin:$PATH\\"\' >> ~/.bashrc\\nsource ~/.bashrc\\n```\\n\\n### Fly.io deployment\\n\\n```bash\\nmkdir fly-tunnel\\ncd fly-tunnel\\nnano fly.toml\\n```\\n\\nNote: you can update `choose-a-subdomain-1234` and `my-user` to any value you\'d like to use.\\n\\n```toml\\n# fly.toml app configuration file\\n#\\n# See https://fly.io/docs/reference/configuration/ for information about how to use this file.\\n#\\n\\napp = \\"choose-a-subdomain-1234\\"\\n\\n[build]\\n  image = \\"ghcr.io/digitallyrefined/docker-wireguard-tunnel:v3\\"\\n\\n[env]\\n  DOMAIN = \\"choose-a-subdomain-1234.fly.dev\\"\\n  PEERS = \\"1\\"\\n  SERVICES = \\"peer1:headscale:80:80,peer1:headscale:443:443\\"\\n\\n[[mounts]]\\n  source = \\"wireguard_data\\"\\n  destination = \\"/etc/wireguard\\"\\n\\n[[services]]\\n  protocol = \\"udp\\"\\n  internal_port = 51820\\n\\n  [[services.ports]]\\n    port = 51820\\n\\n[[services]]\\n  protocol = \\"tcp\\"\\n  internal_port = 80\\n\\n  [[services.ports]]\\n    port = 80\\n\\n[[services]]\\n  protocol = \\"tcp\\"\\n  internal_port = 443\\n\\n  [[services.ports]]\\n    port = 443\\n```\\n\\n### Launching the Fly.io app\\n\\n[Sign up for a Fly.io account](https://fly.io/app/sign-up)\\n\\n:::warning\\n\\nMake sure that you check [Fly.io\'s current free allowances](https://fly.io/docs/about/pricing/#free-allowances), as they may have changed since this guide was last published.\\n\\n:::\\n\\nThis setup uses 1 Fly.io app. As long as you don\'t have more than 3 Fly.io apps running you wont be exceeding [Fly.io\'s free allowance](https://fly.io/docs/about/pricing/#free-allowances) in terms of server usage, however dedicated IPv4 addresses are now a [paid for feature](https://fly.io/docs/about/pricing/#anycast-ip-addresses), so you will need to add a credit card to launch this app. You can use a temporary credit card from [privacy.com](https://privacy.com/) in the US or [Revolut](https://www.revolut.com/) in some parts of Europe.\\n\\n```bash\\nfly auth login\\nfly launch\\n```\\n\\nUse the following options:\\n\\n```\\n? Would you like to copy its configuration to the new app? Yes\\n? Choose an app name (leaving blank will default to \'choose-a-subdomain-1234\') choose-a-subdomain-1234\\n? Choose a region for deployment: Denver, Colorado (US) (den) # Or a location closest to you\\n? Would you like to set up a Postgresql database now? No\\n? Would you like to set up an Upstash Redis database now? No\\n? Would you like to deploy now? Yes\\n? Would you like to allocate a dedicated ipv4 address now? Yes\\n```\\n\\n### Setting up the Fly.io [docker-wireguard-tunnel](https://github.com/DigitallyRefined/docker-wireguard-tunnel)\\n\\nOnce the Fly.io tunnel has started, a `peer1.conf` file will be automatically generated in the `/etc/wireguard` directory, it can be viewed and then removed via:\\n\\n```bash\\nfly ssh console\\ncat /etc/wireguard/peer1.conf\\n# Copy the contents of peer1.conf\\nrm /etc/wireguard/peer1.conf\\n```\\n\\nNow we\'ll create a new folder called `headscale/fly-wireguard` and copy `peer1.conf` to a new file called `wg0.conf`.\\n\\n```bash\\nmkdir -p ~/headscale/fly-wireguard\\nnano ~/headscale/fly-wireguard/wg0.conf\\n```\\n\\n### Install Docker community edition via the convenience script\\n\\n```bash\\ncurl -fsSL https://get.docker.com | sudo bash\\nsudo usermod -aG docker $USER\\n```\\n\\n### Configuring Headscale\\n\\nCreate a headscale folder, import the default configuration and tweak\\n\\n```bash\\ncd ~/headscale\\nmkdir config\\nwget -O ./config/config.yaml https://raw.githubusercontent.com/juanfont/headscale/main/config-example.yaml\\nnano config/config.yaml\\n```\\n\\nSettings to update in the `config/config.yaml` file:\\n\\n```\\nserver_url: https://choose-a-subdomain-1234.fly.dev:443\\nlisten_addr: 0.0.0.0:443\\nacme_email: \\"you@example.com\\"\\ntls_letsencrypt_hostname: \\"choose-a-subdomain-1234.fly.dev\\"\\n```\\n\\n```bash\\nnano docker-compose.yml\\n```\\n\\n```yml\\nversion: \\"2\\"\\nservices:\\n  headscale:\\n    container_name: headscale\\n    image: headscale/headscale\\n    command: \\"headscale serve\\"\\n    restart: unless-stopped\\n    volumes:\\n      - ./config:/etc/headscale/\\n      - ./data:/var/lib/headscale/\\n\\n  fly-wireguard-peer:\\n    container_name: headscale-fly-wireguard-peer\\n    image: ghcr.io/digitallyrefined/docker-wireguard-tunnel:v3\\n    restart: unless-stopped\\n    environment:\\n      # Note that DOMAIN & PEERS are not required for the peer\\n      # Services to expose format (comma-separated)\\n      # SERVICES=peer-id:peer-container-name:peer-container-port:expose-port-as\\n      - SERVICES=peer1:headscale:80:80,peer1:headscale:443:443\\n    cap_add:\\n      - NET_ADMIN\\n    links:\\n      - headscale:headscale\\n    volumes:\\n      - ./fly-wireguard:/etc/wireguard\\n```\\n\\n```bash\\ndocker compose up -d\\ndocker compose logs -f\\n```\\n\\nAfter a few minutes you should now be able to access your new Headscale server by going to your subdomain `https://choose-a-subdomain-1234.fly.dev/swagger`\\n\\n#### Create a new user for your Headscale server\\n\\n```bash\\ndocker exec headscale headscale users create my-user\\n```\\n\\n### Joining Tailscale clients to the network using your custom control server URL\\n\\n* [Windows](https://github.com/juanfont/headscale/blob/main/docs/windows-client.md)\\n* [macOS](https://github.com/juanfont/headscale/issues/106#issuecomment-918843218) (and create a [preauth key](#create-a-new-preauth-key))\\n* [Linux](#docker-compose-setup-to-run-tailscale-on-linux)\\n* [Android](https://github.com/juanfont/headscale/blob/main/docs/android-client.md)\\n* [iOS](https://github.com/juanfont/headscale/blob/main/docs/iOS-client.md)\\n\\n#### Registering a new device and allowing it to join your network\\n\\n```bash\\ndocker exec headscale headscale nodes register --user my-user --key nodekey:...\\n```\\n\\n### Docker compose setup to run Tailscale on Linux\\n\\n#### Create a new preauth key\\n\\n```bash\\ndocker exec headscale headscale --user my-user preauthkeys create --expiration 1h\\n```\\n\\n#### docker-compose.yml\\n\\n```bash\\nmkdir ~/tailscale\\ncd ~/tailscale\\nnano docker-compose.yml\\n```\\n\\nUpdate the `--login-server` URL and `--advertise-routes` to match your network, then add the preauth key to the `TS_AUTHKEY` environment variable (this key only used once on first run to join the network).\\n\\n```yml\\nservices:\\n  tailscale:\\n    container_name: tailscale\\n    image: tailscale/tailscale:stable\\n    hostname: headtailscale\\n    volumes:\\n      - ./data:/var/lib/tailscale\\n      - /dev/net/tun:/dev/net/tun\\n    network_mode: \\"host\\"\\n    cap_add:\\n      - NET_ADMIN\\n      - NET_RAW\\n    environment:\\n      - TS_STATE_DIR=/var/lib/tailscale\\n      - TS_EXTRA_ARGS=--login-server=https://choose-a-subdomain-1234.fly.dev --advertise-exit-node --advertise-routes=192.168.x.0/24 --accept-dns=true\\n      - TS_NO_LOGS_NO_SUPPORT=true\\n      # - TS_AUTHKEY=...\\n    restart: unless-stopped\\n```\\n\\n```bash\\ndocker compose up -d\\ndocker compose logs -f\\n\\ndocker exec headscale headscale nodes list\\ndocker exec headscale headscale routes list\\n\\ndocker exec headscale headscale routes enable -r 1\\ndocker exec headscale headscale routes enable -r 2 # 3 etc\\n\\ndocker exec headscale headscale routes list\\n```\\n\\nNow each of client should be able connect with each other and access local network resources if you have enabled `--advertise-routes=192.168.x.0/24` and also be able to use your home internet connect while you\'re away via Tailscale `-advertise-exit-node` argument.\\n\\n## Additional resources\\n\\n* [How Tailscale works](https://tailscale.com/blog/how-tailscale-works/)\\n* <a href=\\"https://youtu.be/wLrmmh1eI94?t=937\\">Traefik HTTPS tutorial</a>\\n\\n<LiteYouTubeEmbed\\n  id=\\"wLrmmh1eI94\\"\\n  title=\\"Is this the BEST Reverse Proxy for Docker? // Traefik Tutorial\\"\\n  params=\\"start=937\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>"},{"id":"/guides/IKEA-VINDSTYRKA","metadata":{"permalink":"/guides/IKEA-VINDSTYRKA","editUrl":"https://github.com/DigitallyRefined/DigitallyRefined.github.io/tree/main/blog/2023-05-14-IKEA-VINDSTYRKA.mdx","source":"@site/blog/2023-05-14-IKEA-VINDSTYRKA.mdx","title":"IKEA VINDSTYRKA","description":"The IKEA VINDSTYRKA an relatively inexpensive air quality monitor $49/\xa335 that was released in April 2023.","date":"2023-05-14T00:00:00.000Z","tags":[{"inline":true,"label":"Reviews","permalink":"/tags/reviews"},{"inline":true,"label":"Home Assistant","permalink":"/tags/home-assistant"},{"inline":true,"label":"Smart Home","permalink":"/tags/smart-home"},{"inline":true,"label":"Hardware","permalink":"/tags/hardware"},{"inline":true,"label":"YouTube","permalink":"/tags/you-tube"},{"inline":true,"label":"Video","permalink":"/tags/video"}],"readingTime":1.19,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"/guides/IKEA-VINDSTYRKA","tags":["Reviews","Home Assistant","Smart Home","Hardware","YouTube","Video"],"last_update":{"date":"2026-01-07T00:00:00.000Z"}},"unlisted":false,"lastUpdatedAt":1767744000000,"prevItem":{"title":"Tailscale & Headscale","permalink":"/guides/Tailscale-Headscale-setup"}},"content":"The IKEA VINDSTYRKA an relatively inexpensive air quality monitor $49/\xa335 that was released in April 2023.\\n\\n{/* truncate */}\\n\\nimport TOCInline from \'@theme/TOCInline\';\\n\\n<TOCInline toc={toc} />\\n\\n## Video\\n\\nimport LiteYouTubeEmbed from \'react-lite-youtube-embed\';\\nimport \'react-lite-youtube-embed/dist/LiteYouTubeEmbed.css\'\\n\\n<LiteYouTubeEmbed\\n  id=\\"EvjTHlPT9zM\\"\\n  title=\\"IKEA VINDSTYRKA Review & Pairing to Home Assistant\\"\\n  poster=\\"maxresdefault\\"\\n  webp\\n/>\\n\\n<a href=\\"https://youtu.be/EvjTHlPT9zM\\">Watch on YouTube</a>\\n\\n## Features\\n\\n* PM2.5\\n* tVOC\\n* Temperature\\n* Humidity\\n* Air quality icons\\n* Zigbee radio\\n* USB-C\\n\\n## Pros\\n\\n* Relatively inexpensive way to add air quality, temperature & humidity data to your smart home\\n* Can perform automatons based on data, such as turning on/off air purifiers, air conditioning and dehumidifiers or even humidifiers\\n* Configurable backlight brightness & always on or auto off\\n* Works with Home Assistant via Zigbee\\n* USB-C powered\\n\\n## Cons\\n\\n* No time or date on display (LCD limitation)\\n* Fan does make small amount of noise\\n* Temperature lacks decimal places (precision)\\n* Getting the tVOC value via ZHA requires a bit more setup\\n* Only available in white\\n* No battery\\n\\n## Home Assistant integration\\n\\nIt\'s compatible both with the built-in Home Assistant [ZHA integration](https://www.home-assistant.io/integrations/zha/) and the [Zigbee2MQTT plug-in](https://github.com/zigbee2mqtt/hassio-zigbee2mqtt#installation).\\n\\nThe video and this article previously mentioned that the tVOC sensor was not available via ZHA, but it was [added in a later release](https://github.com/zigpy/zha-device-handlers/pull/3801).\\n\\nSee also: [differences between ZHA and Zigbee2MQTT](https://youtu.be/RWzzNe5gm5s)."}]}}')}}]);